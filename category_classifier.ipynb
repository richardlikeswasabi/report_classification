{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Visualisation tools\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import seaborn as sns\n",
    "\n",
    "# Processing tools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# sklearn tools\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# imblearn samplers\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7251655629139073\n"
     ]
    }
   ],
   "source": [
    "def read_csv(file_path, scramble=False):\n",
    "    if scramble:\n",
    "        return (pd.read_csv(file_path).sample(frac=1));\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def pre_process(df, train=True):\n",
    "    if train:\n",
    "        df = df.dropna(subset=['Classification'])\n",
    "        \n",
    "    df = df.fillna('')\n",
    "    df['Incident Summary'] = df['Short Description'] + \" \" + \\\n",
    "                             df['Summary'] + \" \" + \\\n",
    "                             df['Root Cause'] + \" \" + \\\n",
    "                             df['Mechanism of Injury Description']\n",
    "    if train:\n",
    "        #show_class_distribution(df)\n",
    "        df = df[['Incident Date', 'Incident Summary', 'Classification']]\n",
    "        df['category_id'] = df['Classification'].factorize()[0]\n",
    "        category_id_df = df[['Classification', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "        category_to_id = dict(category_id_df.values)\n",
    "        id_to_category = dict(category_id_df[['category_id', 'Classification']].values)\n",
    "    else:\n",
    "        df = df[['Incident Number', 'Incident Date', 'Incident Summary']]\n",
    "    \n",
    "    if train: \n",
    "        return (df, category_id_df, category_to_id, id_to_category)\n",
    "    else:\n",
    "        return (df)\n",
    "\n",
    "def show_class_distribution(df):\n",
    "    fig = plt.figure()\n",
    "    df.groupby('Classification').Classification.count().plot.bar(ylim=0)\n",
    "    plt.show()\n",
    "\n",
    "def train_svm(df, category_id_df, category_to_id, id_to_category, analysis=False):\n",
    "    tfidf = TfidfVectorizer(sublinear_tf=False, min_df=3,\n",
    "                            ngram_range=(1,3), stop_words='english')\n",
    "    features = tfidf.fit_transform(df['Incident Summary']).toarray()\n",
    "    labels = df.category_id\n",
    "    \n",
    "    # Show features from tfidf\n",
    "    #show_features(tfidf, features, labels, category_to_id)\n",
    "\n",
    "    # Test different classifier models\n",
    "    #test_models(df, features, labels)\n",
    "    \n",
    "    model = LinearSVC(C=1,random_state=1)\n",
    "    X_train, X_test, y_train, y_test, indices_train, indices_test = \\\n",
    "                train_test_split(features, labels, df.index, test_size=0.3, random_state=0)\n",
    "    \n",
    "    # Undersample 'Other' class and oversample others\n",
    "    sm = RandomOverSampler(random_state=1)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "    # Fit model with resampled data\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    print(\"Model Accuracy:\", accuracy)\n",
    "\n",
    "    if analysis:\n",
    "        # Show model metrics\n",
    "        show_metrics(y_test, y_pred, df)\n",
    "\n",
    "        # Confusion matrix\n",
    "        conf_mat = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "                xticklabels=category_id_df['Classification'].values, \n",
    "                yticklabels=category_id_df['Classification'].values)\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "\n",
    "        # Display table where number of incorrectly classified cases > 2\n",
    "        pd.set_option('display.max_colwidth', -1)\n",
    "        for predicted in category_id_df.category_id:\n",
    "            for actual in category_id_df.category_id:\n",
    "                if predicted != actual and conf_mat[actual, predicted] >= 2:\n",
    "                  print(\"'{}' predicted as '{}' : {} examples.\".format(id_to_category[actual], id_to_category[predicted], conf_mat[actual, predicted]))\n",
    "                  display(df.loc[indices_test[(y_test == actual) & (y_pred == predicted)]][['Classification', 'Incident Summary']])\n",
    "                  print('')\n",
    "\n",
    "        # Show models features\n",
    "        model.fit(features, labels)\n",
    "        N = 2\n",
    "        for Product, category_id in sorted(category_to_id.items()):\n",
    "          indices = np.argsort(model.coef_[category_id])\n",
    "          feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "          unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]\n",
    "          bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]\n",
    "          print(\"# '{}':\".format(Product))\n",
    "          print(\"  . Top unigrams:\\n       . {}\".format('\\n       . '.join(unigrams)))\n",
    "          print(\"  . Top bigrams:\\n       . {}\".format('\\n       . '.join(bigrams)))\n",
    "    \n",
    "    return(tfidf, model)\n",
    "\n",
    "def predict(df, tfidf, model, id_to_category, output_csv=False):\n",
    "    df = pre_process(df, train=False)\n",
    "    features = tfidf.transform(df['Incident Summary']).toarray()\n",
    "\n",
    "    y_pred = model.predict(features)\n",
    "    df['predicted'] = [id_to_category[pred] for pred in y_pred]\n",
    "    \n",
    "    if output_csv:\n",
    "        df.to_csv('yay.csv')\n",
    "\n",
    "\n",
    "def show_features(tfidf, features, labels, category_to_id):\n",
    "    N = 2\n",
    "    for Classification, category_id in sorted(category_to_id.items()):\n",
    "        features_chi2 = chi2(features, labels == category_id)\n",
    "        indices = np.argsort(features_chi2[0])\n",
    "        feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "        unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "        bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "        print(\"# '{}':\".format(Classification))\n",
    "        print(\"Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "        print(\"Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n",
    "        \n",
    "def test_models(df, features, labels):\n",
    "    models = [\n",
    "        RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "        #DecisionTreeClassifier(),\n",
    "        KNeighborsClassifier(),\n",
    "        LinearSVC(),\n",
    "        SGDClassifier(loss='hinge', class_weight='balanced'),\n",
    "        MultinomialNB(),\n",
    "        #MLPClassifier(),\n",
    "        #GradientBoostingClassifier(),\n",
    "        #LogisticRegression(random_state=0),\n",
    "    ]\n",
    "    CV = 10\n",
    "    cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "    entries = []\n",
    "    for model in models:\n",
    "      model_name = model.__class__.__name__\n",
    "      accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "      for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n",
    "    sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "    sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "                  size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "    plt.show()\n",
    "    print(cv_df.groupby('model_name').accuracy.mean())\n",
    "\n",
    "def show_metrics(y_test, y_pred, df):\n",
    "    print(metrics.classification_report(y_test, y_pred, target_names=df['Classification'].unique()))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"incidents.csv\"    \n",
    "    df = read_csv(path)\n",
    "    labelled_df, category_id_df, category_to_id, id_to_category = pre_process(df)\n",
    "    tfidf, model = train_svm(labelled_df, category_id_df, \n",
    "                             category_to_id, id_to_category, analysis=False)\n",
    "    predict(df, tfidf, model, id_to_category, output_csv=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
