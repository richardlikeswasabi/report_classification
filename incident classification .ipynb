{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.9850560398505604\n",
      "Non Grid Test acc: 0.7711442786069652\n"
     ]
    }
   ],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "        self.date = []\n",
    "        self.id = []\n",
    "            \n",
    "def read_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    train = Data()\n",
    "    test = Data()\n",
    "    unseen = Data()\n",
    "    classified = Data()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        string = (str(row['Short Description'])+(row['Summary']))\n",
    "        label = str(row['Classification'])\n",
    "        date = str(row['Incident Date'])\n",
    "        counter = str(row['Incident Number'])\n",
    "        if label != 'nan':\n",
    "            classified.date.append(date)\n",
    "            classified.data.append(string)\n",
    "            classified.label.append(label)\n",
    "            classified.id.append(counter)\n",
    "        unseen.date.append(date)        \n",
    "        unseen.data.append(string)\n",
    "        unseen.label.append(label)\n",
    "        unseen.id.append(counter)\n",
    "\n",
    "    # train:test ratio\n",
    "    train.data, test.data, train.label, test.label = train_test_split(classified.data, \n",
    "                                                                      classified.label, \n",
    "                                                                      test_size=0.2, \n",
    "                                                                      random_state = 5) \n",
    "\n",
    "    return train, test, unseen\n",
    "\n",
    "def create_clf(clf_type):\n",
    "    if clf_type == \"NB\":\n",
    "        text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                             ('tfidf', TfidfTransformer()),\n",
    "                             ('clf', MultinomialNB())])\n",
    "        parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                      'tfidf__use_idf': (True, False),\n",
    "                      'clf__alpha': (1e-2, 1e-3)}\n",
    "    elif clf_type == \"SVM\":\n",
    "        text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                             ('tfidf', TfidfTransformer()),\n",
    "                             ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                                   alpha=1e-3,  \n",
    "                                                   max_iter=5000,\n",
    "                                                   tol=1e-3,\n",
    "                                                   random_state=42))\n",
    "                             ])\n",
    "        parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                      'tfidf__use_idf': (True, False),\n",
    "                      'clf__alpha': (1e-2, 1e-3)}    \n",
    "\n",
    "    return text_clf, parameters\n",
    "\n",
    "def model(MODEL,unseen):\n",
    "    \n",
    "    train, test, unseen = read_csv(path) \n",
    "        \n",
    "    text_clf, parameters = create_clf(MODEL);\n",
    "    text_clf = text_clf.fit(train.data, train.label)\n",
    "\n",
    "    predicted  = text_clf.predict(train.data)\n",
    "    print(\"Training acc:\",  np.mean(predicted == train.label))\n",
    "\n",
    "    predicted = text_clf.predict(test.data)\n",
    "    print(\"Non Grid Test acc:\",  np.mean(predicted == test.label))\n",
    "    while np.mean(predicted == test.label) < 0.5:\n",
    "        train, test, unseen = read_csv(path)\n",
    "        text_clf, parameters = create_clf(MODEL);\n",
    "        text_clf = text_clf.fit(train.data, train.label)\n",
    "        # Using grid search\n",
    "        gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1, cv=3, iid=False)\n",
    "        gs_clf = gs_clf.fit(train.data, train.label)\n",
    "        predicted = gs_clf.predict(test.data)\n",
    "        print(\"Grid Test acc:\",  np.mean(predicted == test.label))\n",
    "\n",
    "        # Testing against unseen \n",
    "    prediction = text_clf.predict(unseen.data)\n",
    "    \n",
    "    #print(\"Grid Test acc:\",  np.mean(predicted == test.label))\n",
    "  \n",
    "    df = pd.DataFrame({'number' : unseen.id ,'desc' : unseen.data, 'category' : prediction, 'date' : unseen.date}) \n",
    "    df.to_csv('designclass_modified.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"incidents.csv\"    \n",
    "    train, test, unseen = read_csv(path) \n",
    "    MODEL = \"SVM\"\n",
    "    model(MODEL,unseen)\n",
    "    excel_col = [\"desc\",\"design\",\"date\",\"number\"]\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_graph(data):\n",
    "    yes_dict = {}\n",
    "    no_dict = {}\n",
    "    for i in range(len(data.data)):\n",
    "        if data.label[i] == 'y':\n",
    "            if len(data.date[i].split('/')) != 3:\n",
    "                continue\n",
    "\n",
    "            date = data.date[i].split('/')[2]\n",
    "            if date not in yes_dict:\n",
    "                yes_dict[date] = 1\n",
    "            else:\n",
    "                yes_dict[date] += 1\n",
    "\n",
    "        elif data.label[i] == 'n':\n",
    "            if len(data.date[i].split('/')) != 3:\n",
    "                continue\n",
    "\n",
    "            date = data.date[i].split('/')[2]\n",
    "            if date not in no_dict:\n",
    "                no_dict[date] = 1\n",
    "            else:\n",
    "                no_dict[date] += 1\n",
    "\n",
    "    no_dict = OrderedDict(sorted(no_dict.items()))\n",
    "    yes_dict = OrderedDict(sorted(yes_dict.items()))\n",
    "\n",
    "    non_design = go.Bar(\n",
    "        x=[key for key in no_dict],\n",
    "        y=[no_dict[key] for key in no_dict],\n",
    "        name='Non-Design Related',\n",
    "\tmarker=dict(\n",
    "\t    color='rgb(55, 83, 109)'\n",
    "\t)\n",
    "    )\n",
    "    design = go.Bar(\n",
    "        x=[key for key in yes_dict],\n",
    "        y=[yes_dict[key] for key in yes_dict],\n",
    "        name='Design Related',\n",
    "\tmarker=dict(\n",
    "\t    color='rgb(26, 118, 255)'\n",
    "\t)\n",
    "    )\n",
    "    \n",
    "    data = [non_design, design]\n",
    "    layout = go.Layout(\n",
    "        title='Sydney Water Design vs Non-Design Related Incidents (2013-Present)',\n",
    "        barmode='group',\n",
    "\txaxis = {'title': 'Years'},\n",
    "\tyaxis = {'title': 'Number of Incidents'}\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    \"\"\" To save to file, py.iplot(fig, filename='whatever_name') \"\"\"\n",
    "    # For Jupyter uncomment line below\n",
    "    #py.iplot(fig)\n",
    "    # For Python uncomment line below\n",
    "    py.plot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
